\section{\revb{Spiking Neural Networks and Event-Based Vision}}

\revb{Rods and cones in the visual system sense stimuli of different wavelengths. They apply different weights to input stimuli and accumulate logarithmic responses to represent chrominance (color) and luminance (brightness). These signals feed the associative cortex for object linking and the occipital cortex for pattern processing. Visual cells provide hierarchical responses}~\cite{hubel1979brain, riesenhuber1999hierarchical}. \revb{Simple visual cells track general structure while complex visual cells detect fine details. This hierarchical concept underlies neuromorphic vision sensors and spiking neural networks. The Dynamic Vision Sensor (DVS)}~\cite{lichtsteiner2008128} \revb{draws inspiration from the ``transient'' pathway, a component of the visual system that detects dynamic visual information. This ``transient'' pathway comprises 30\% of the visual system}~\cite{steffen2019neuromorphic}.

\revb{Event-based bio-sensors}~\cite{lichtsteiner2008128} \revb{trigger output spikes at pixel locations whenever brightness changes logarithmically exceed a threshold value. Similarly, neurons connected to event-based sensors hierarchically trigger spikes when their state surpasses threshold values. The initial layers of this receptive field implement difference of Gaussian filters for detecting edges and corners, and Gabor filters for detecting edge orientation. The receptive field becomes more complex in deeper layers to detect detailed features. Neurons in SNNs do not generate output spikes without receiving input spikes, meaning computation is skipped on inactive neurons, thereby conserving energy. In contrast, traditional convolutional networks compute on all regions at fixed time intervals}~\cite{camunas2014event, gallego2019event}. \revb{Feeding event-based data to neuromorphic systems avoids energy-inefficient conversion from regular input patterns to spike sequences}~\cite{wang2017energy}.

\subsection{Neuromorphic computing}
\revb{Neuromorphic computing focuses on designing energy and space-efficient systems inspired by neuroscientific insights into neocortex behavior}~\cite{merollad2014million}. \revb{The mammalian cortex comprises approximately 100 billion neurons, each connecting to 10 to 10,000 synapses. Current silicon technology cannot replicate this brain structure. However, advances following Moore's law have enabled several large-scale neuromorphic processor designs}~\cite{li2016heterogeneous} \revb{including IBM TrueNorth}~\cite{akopyan2015truenorth}, \revb{Intel Loihi}~\cite{davies2018loihi}, \revb{Stanford Neurogrid}~\cite{benjamin2014neurogrid}, \revb{Heidelberg BrainScaleS}~\cite{schmitt2017neuromorphic}, \revb{and Manchester SpiNNaker}~\cite{furber2014spinnaker}. \revb{A comprehensive review of large-scale neuromorphic systems is available in}~\cite{furber2016large}, \revb{and Figure~\ref{neurochips} compares these systems. However, designing and fabricating new technology-based systems incurs significant cost and time. Reconfigurable hardware design on FPGAs provides a solution that adapts to different technologies based on available resources.}

\subsection{FPGAs for event-based processing}
\revb{Compared to CPUs and GPUs, FPGAs provide higher throughput and energy efficiency for SNNs}~\cite{sripad2018snava}. \revb{FPGAs offer flexibility and eliminate the lengthy, costly ASIC chip design and fabrication process}~\cite{maguire2007challenges}. \revb{With register transfer level (RTL) code, the only implementation constraint is available FPGA resources, independent of technology. RTL code for spiking networks can be generated via high-level synthesis (HLS) tools based on C++ and C}~\cite{pearson2005design} \revb{or direct implementation in Verilog or VHDL. Although hardware description language (HDL) code}~\cite{akbarzadeh2018scalable} \revb{enables low-level optimization for SNNs, HLS, OpenCL, or MATLAB toolboxes facilitate faster FPGA prototyping}~\cite{alfaro2019improving, alfaro2019prototyping, jin2019simulation, wu2015development}.

\textbf{\revb{FPGAs for Real-Time Simulation of SNNs for Neurobiological Disorders:}} \revb{Parallel simulation of neurons on FPGAs enables analysis of neurobiological disorders}~\cite{khoyratee2019optimized, han2020hardware}. \revb{Discovering neuroprostheses requires stimulating neuronal cells with desired states, which real-time neuron emulators can achieve}~\cite{khoyratee2019biomimetic, zbrzeski2016bio}. \revb{Parallel neuron models also advance understanding of brain function}~\cite{yang2018fpga} \revb{and can even replace damaged neurons}~\cite{ambroise2013biorealistic}. \revb{FPGA-based SNN designs can incorporate parallel self-repair capability through spiking astrocyte neural networks}~\cite{karim2018fpga, karim2020astrobyte, johnson2017homeostatic}.


\textbf{\revb{Routing and Communication on FPGAs:}} \revb{FPGA routing cannot accommodate the high connectivity inherent in complex SNNs. Each neuron in the brain connects to 1,000--10,000 synapses, presenting a challenge given FPGAs' limited routing capability}~\cite{harkin2009reconfigurable}. \revb{This high connectivity enables fault-tolerant systems; in the brain, this property is termed graceful degradation, whereby neurons continually lose connectivity without noticeably degrading brain function. Network-on-Chip (NoC) structures}~\cite{carrillo2012advancing, cawley2011hardware, morgan2009exploring, renzini2019quantitative, luo2018fpga, zhang2019asynchronous} \revb{optimize spike packet transfer between configurable logic blocks on shared FPGA buses, assuming dense connectivity in SNNs. NoC protocols also enhance spiking network scalability and interneuron communication. Various NoC routing techniques exist, including Manhattan-style routing}~\cite{rubin2003design} \revb{and multi-stage switching}~\cite{renzini2019quantitative}, \revb{representing early and recent methods respectively.}

\textbf{\revb{Compute-Efficient FPGAs:}} \revb{FPGA platforms cost-efficiently emulate large-scale neuromorphic architectures}~\cite{valancius2020fpga, wang2020sies}. \revb{Compute-efficient techniques such as approximate computing}~\cite{wang2017energy, wang2016liquid}, \revb{which eliminates redundant computation, enable SNN viability on FPGAs. Multiplication operations can be replaced with CORDIC algorithms and lookup tables to improve computational efficiency}~\cite{heidarpur2019cordic}. \revb{Reducing weight precision data width}~\cite{zambelli2018half} \revb{eliminates redundant processing inherent in full-precision implementations. Memory hierarchy optimization reduces memory accesses and consequent power dissipation}~\cite{nallathambi2020probabilistic, saha2020cynapse}.


\textbf{\revb{Learning and Inference on FPGAs:}} \revb{Three significant neuron models exist for implementing SNN inference. The most complex is the Hodgkin-Huxley equations}~\cite{alfaro2019prototyping, kousanakis2017architecture}, \revb{while simpler models including Izhikevich}~\cite{lammie2018unsupervised, choi2015implementation} \revb{and leaky integrate-and-fire}~\cite{slepova2018synthesis, han2020hardware, guo2019systolic, yi2019implementation, roshdy2020generic, wan2016efficient, mostafa2017fast} \revb{offer promising simplicity and accuracy for FPGA implementation. One SNN training approach is self-supervised learning via spike-timing-dependent plasticity (STDP)}~\cite{lammie2018unsupervised, wang2017energy, heidarpur2019cordic, kuang2019digital, xia2020real, liu2019energy}. \revb{However, this method does not match supervised learning methods on ANNs. An alternative approach trains with supervised backpropagation on ANNs, then converts weight values to SNNs}~\cite{ju2020fpga, wang2020sies}. \revb{Typically, acceleration targets SNN inference on FPGAs while models are trained in software with weight updates streamed to hardware}~\cite{walravens2019spiking}.


\textbf{\revb{FPGAs for Event-Based Sensors:}} \revb{Spike outputs from event-based camera sensors can directly feed spiking neural networks for pattern recognition}~\cite{camunas2019low}. \revb{SNNs accurately process visual features}~\cite{sun2017spiking}. \revb{FPGAs enable high-speed event packet transmission and noise removal}~\cite{linares2015usb3, linares2019low}. \revb{Parallel FPGA structures accelerate vital algorithms including optical flow calculation and object detection}~\cite{liu2017block, aung2018event, liu2019live}. \revb{Coupling FPGAs with DVS sensors enables accurate frequency extraction from fast-rotating objects}~\cite{hoseini2018real, rios2015real}. \revb{Real-time histogram creation on FPGAs is significant for object tracking and optical flow calculation}~\cite{sethi2019optimized, pivezhandi2020ParaHist}.
